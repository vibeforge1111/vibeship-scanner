<!-- MIND:VERSION:2 -->
## Memory (Mind)

This project uses Mind for persistent memory across sessions.

### Required Protocol

1. **Session Start**: ALWAYS call `mind_recall()` before responding to the first message. This loads context from previous sessions.

2. **During Work**: Use `mind_log(message, type)` to capture what happens:
   - `mind_log("chose X over Y - simpler", type="decision")` -> MEMORY.md
   - `mind_log("API returns 500 on large payloads", type="problem")` -> MEMORY.md
   - `mind_log("Safari needs vendor prefix for X", type="learning")` -> MEMORY.md
   - `mind_log("resolved by increasing timeout", type="progress")` -> MEMORY.md
   - `mind_log("working on auth flow", type="experience")` -> SESSION.md
   - `mind_log("build keeps failing", type="blocker")` -> SESSION.md
   - `mind_log("tried Redis - too complex", type="rejected")` -> SESSION.md
   - `mind_log("assuming user has stable internet", type="assumption")` -> SESSION.md

3. **Session End**: Summarize with `## DATE | what happened | mood: X`

### Two-Layer Memory

**MEMORY.md** (permanent, cross-session):
- Decisions, learnings, problems, progress
- Use types: `decision`, `learning`, `problem`, `progress`

**SESSION.md** (ephemeral, within-session):
- Raw experience, blockers, rejected approaches, assumptions
- Use types: `experience`, `blocker`, `rejected`, `assumption`
- Valuable items get promoted to MEMORY.md on session gap (>30 min)

### Tools Available

- `mind_recall()` - Load session context (CALL FIRST!)
- `mind_log(msg, type)` - Log to session or memory (routes by type)
- `mind_session()` - Get current session state
- `mind_blocker(description)` - Log blocker + auto-search memory for solutions
- `mind_search(query)` - Find specific memories
- `mind_remind(msg, when)` - Set time or context reminder
- `mind_checkpoint()` - Force process pending memories
- `mind_edges(intent)` - Check for gotchas before coding
- `mind_status()` - Check memory health

---

<!-- MIND:CONTEXT - Auto-generated by Mind. Do not edit. -->
## Stack
sveltekit, typescript, supabase

## Supabase Configuration (IMPORTANT)
**Current Supabase Project**: `kgxjubeaddrocooklyib`
- **URL**: `https://kgxjubeaddrocooklyib.supabase.co`
- **API Key**: See `.env` file for `VITE_SUPABASE_ANON_KEY`
- **Note**: Old project `jryabrpfzwtdqvnemqgj` is defunct - DO NOT USE

## Gotchas
(None yet - add to .mind/MEMORY.md Gotchas section)


# CLAUDE.md - Vibeship Scanner Development Guide

This file provides guidance to Claude Code when working with this repository.

## Project Overview

Vibeship Scanner is a security scanning tool that analyzes GitHub repositories for vulnerabilities using:
- **Opengrep** - Static Application Security Testing (SAST) - open-source Semgrep fork
- **Trivy** - Dependency vulnerability scanning
- **Gitleaks** - Secret detection

---

## ğŸš¨ ULTIMATE RULE: VERIFICATION-FIRST METHODOLOGY ğŸš¨

**THIS IS THE PRIMARY, NON-NEGOTIABLE RULE FOR ALL SCANNER WORK**

### The Golden Rule

> **Coverage = What our SCAN RESULTS actually detect vs What the REPO DOCUMENTS it contains**
>
> NOT: "We have rules for X" â†’ We must PROVE we detect X with actual scan evidence

### Verification Protocol (MANDATORY)

For EVERY benchmark repo, verification requires THREE sources of truth:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. REPO'S OWN DOCUMENTATION                                                â”‚
â”‚     â””â”€ What vulns does the repo's README/wiki/docs claim to contain?        â”‚
â”‚     â””â”€ This is the GROUND TRUTH - what we're trying to detect               â”‚
â”‚                                                                             â”‚
â”‚  2. OUR ACTUAL SCAN RESULTS                                                 â”‚
â”‚     â””â”€ Query findings from Supabase for the scan ID                         â”‚
â”‚     â””â”€ Real findings with file paths, line numbers, rule IDs                â”‚
â”‚                                                                             â”‚
â”‚  3. COMPARISON TABLE                                                        â”‚
â”‚     â””â”€ Map each documented vuln to actual scan findings                     â”‚
â”‚     â””â”€ Calculate: detected / SAST-detectable = coverage %                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Counts as "Verified Detected"

A vulnerability is âœ… ONLY if ALL of these are true:
1. The repo documents it exists (README, wiki, or challenge description)
2. Our scan has a finding for that vuln type
3. The finding is in the correct file that implements the vuln
4. We can cite: `rule_id`, `file:line`, `scan_id`

### What Does NOT Count

âŒ "We have rules for SQL injection" - MUST show actual finding
âŒ "The scan found 500 findings" - MUST map to documented vulns
âŒ "Previous session said 90%" - MUST re-verify with current scan
âŒ Estimates, assumptions, or "should detect"

### Improvement Workflow

```
SCAN â†’ COMPARE TO REPO DOCS â†’ IDENTIFY GAPS â†’ ADD RULES â†’ RESCAN â†’ VERIFY
         â†‘                                                           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Iterate until 100% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Session Checklist

Before claiming any coverage percentage:
- [ ] Fetched repo's README/docs for documented vulns
- [ ] Ran scan and have scan ID
- [ ] Queried actual findings from Supabase
- [ ] Created comparison table with evidence
- [ ] Calculated coverage from ACTUAL data

**If you cannot cite scan_id + rule_id + file:line, you have NOT verified.**

---

## IMPORTANT: How to Trigger Scans

**ALWAYS use the deployed Vibeship Scanner API for scans** - never run local semgrep/opengrep commands directly.

### Scan Procedure (MUST FOLLOW)

```bash
# 1. Generate a UUID for the scan
SCAN_ID=$(python -c "import uuid; print(uuid.uuid4())")

# 2. Trigger the scan via curl
curl -X POST https://scanner-empty-field-5676.fly.dev/scan \
  -H "Content-Type: application/json" \
  -d "{\"scanId\": \"$SCAN_ID\", \"repoUrl\": \"https://github.com/OWNER/REPO\"}"

# 3. Provide the scan URLs to the user
echo "View at: http://localhost:5173/scan/$SCAN_ID"
echo "View at: https://scanner.vibeship.co/scan/$SCAN_ID"
```

### Quick One-Liner Template
```bash
SCAN_ID=$(python -c "import uuid; print(uuid.uuid4())") && \
echo "Scan ID: $SCAN_ID" && \
echo "View at: http://localhost:5173/scan/$SCAN_ID" && \
echo "View at: https://scanner.vibeship.co/scan/$SCAN_ID" && \
curl -X POST https://scanner-empty-field-5676.fly.dev/scan \
  -H "Content-Type: application/json" \
  -d "{\"scanId\": \"$SCAN_ID\", \"repoUrl\": \"https://github.com/OWNER/REPO\"}"
```

### View Results At
- **Local dev**: `http://localhost:5173/scan/<scanId>`
- **Production**: `https://scanner.vibeship.co/scan/<scanId>`

### Why This Matters
1. Results are saved to Supabase and viewable in the web UI
2. All four scanners run (Opengrep + Trivy + Gitleaks + npm audit)
3. Consistent rule versions from deployed scanner
4. Scan progress is tracked in real-time

### Monitoring Scans
```bash
# Watch scanner logs in real-time
fly logs -a scanner-empty-field-5676

# Get recent logs (no streaming)
fly logs -a scanner-empty-field-5676 --no-tail | tail -100
```

### Common Issues
- **Scan stuck in "scanning"**: Check Fly.io logs for errors
- **Database errors**: Ensure scan row is created with proper schema (target_url, target_url_hash, target_branch)
- **Deployment kills running scans**: Fly.io restarts terminate in-progress scans - wait for completion before deploying

## Architecture

```
vibeship-scanner/
â”œâ”€â”€ src/                    # SvelteKit frontend
â”‚   â”œâ”€â”€ routes/             # Pages and API routes
â”‚   â”œâ”€â”€ lib/                # Shared utilities
â”‚   â””â”€â”€ app.html            # HTML template
â”œâ”€â”€ scanner/                # Python scanner service (Fly.io)
â”‚   â”œâ”€â”€ scan.py             # Main scanning orchestrator
â”‚   â”œâ”€â”€ server.py           # Flask API server
â”‚   â”œâ”€â”€ rules/              # Semgrep rule files
â”‚   â”‚   â”œâ”€â”€ core.yaml       # Core security rules
â”‚   â”‚   â””â”€â”€ vibeship.yaml   # Extended rules
â”‚   â””â”€â”€ Dockerfile          # Scanner container
â””â”€â”€ docs/                   # Documentation
```

## Development Commands

```bash
# Start frontend dev server
npm run dev

# Build for production
npm run build

# Deploy scanner to Fly.io
cd scanner && fly deploy --remote-only

# Validate Semgrep rules
semgrep --validate --config scanner/rules/
```

## Key Files

- `scanner/rules/core.yaml` - Core Semgrep security rules
- `scanner/rules/vibeship.yaml` - Extended Semgrep rules
- `scanner/scan.py` - Main scanning logic
- `src/routes/api/scan/+server.ts` - Scan API endpoint
- `src/routes/scan/[id]/+page.svelte` - Scan results page

## Security Knowledge Base

### IMPORTANT: Maintaining SECURITY_COMMONS.md

The `SECURITY_COMMONS.md` file is our **living security vulnerability database**. It must be continuously updated with:

1. **New vulnerability patterns** discovered during:
   - Research on vulnerable applications (DVWA, Juice Shop, etc.)
   - Analysis of GitHub security advisories
   - Review of scan results from real repositories
   - CVE database monitoring

2. **For each vulnerability, document**:
   - CWE ID and name
   - Risk level (Critical/High/Medium/Low)
   - Vulnerable code examples
   - Secure code examples
   - Key prevention points

3. **Use this database to**:
   - Improve Semgrep rules in `scanner/rules/`
   - Enhance scanner explanations
   - Provide accurate fix recommendations
   - Train and validate scanner accuracy

4. **After finding new vulnerabilities**:
   - Add to SECURITY_COMMONS.md with examples
   - Consider adding new Semgrep rules if detectable
   - Update SECURITY_TEST_PROCEDURE.md if needed

### Testing Against Vulnerable Apps

**IMPORTANT**: Follow `SECURITY_TEST_PROCEDURE.md` for systematic scanner improvement.

The test procedure contains **30 vulnerable repositories** organized by priority:
- **Tier 1 (Critical)**: DVWA, Juice Shop, crAPI, NodeGoat, WebGoat, DVNA
- **Tier 2 (Language-Specific)**: RailsGoat, Django.nV, Flask, DSVW, PHP, Java apps
- **Tier 3 (Specialized)**: API security, SSRF, XXE, GraphQL, CI/CD, secrets
- **Tier 4 (Additional)**: Mobile, .NET, Kubernetes, CTF tools

**Iterative Improvement Workflow (MUST FOLLOW)**:

For each vulnerable repository, iterate until all key vulnerabilities are detected:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. INITIAL SCAN                                            â”‚
â”‚     - Trigger scan using the scan procedure above           â”‚
â”‚     - Save scan ID for comparison                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. GAP ANALYSIS                                            â”‚
â”‚     - Review the repo's README/docs for known vulns         â”‚
â”‚     - Check what OWASP Top 10 vulns the repo claims to have â”‚
â”‚     - Compare against our scan findings                     â”‚
â”‚     - List missing detections (gaps)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. RULESET UPGRADE                                         â”‚
â”‚     - Create new Opengrep rules for gaps                    â”‚
â”‚     - Validate rules: opengrep --validate -f rule.yaml      â”‚
â”‚     - Deploy: cd scanner && fly deploy --remote-only        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. RE-SCAN & DIFF                                          â”‚
â”‚     - Trigger new scan on same repo (new scan ID)           â”‚
â”‚     - Use the diff tool to compare old vs new findings      â”‚
â”‚     - Verify new rules caught the gaps                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. ITERATE OR COMPLETE                                     â”‚
â”‚     - If gaps remain â†’ go back to step 2                    â”‚
â”‚     - If all key vulns detected â†’ document and commit       â”‚
â”‚     - Update SECURITY_TEST_PROCEDURE.md with results        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Gap Analysis Checklist**:
- [ ] SQL Injection (if repo has database)
- [ ] XSS (if repo has web UI)
- [ ] Command Injection (if repo runs shell commands)
- [ ] Path Traversal (if repo handles file paths)
- [ ] SSRF (if repo makes HTTP requests)
- [ ] Insecure Deserialization (if repo deserializes data)
- [ ] Hardcoded Secrets (API keys, passwords)
- [ ] Broken Authentication (weak session handling)
- [ ] Security Misconfiguration (debug mode, CORS)
- [ ] Vulnerable Dependencies (outdated packages)

**Current Verified Benchmark Coverage** (as of Dec 2024):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VIBESHIP SCANNER - VERIFIED BENCHMARK (32 repos, 60,000+ findings)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TIER 1 (Critical - 6 repos):                                               â”‚
â”‚  â”œâ”€ DVWA (PHP)            151 findings   SQL, XSS, Command Inj, LFI        â”‚
â”‚  â”œâ”€ Juice Shop (JS)       931 findings   OWASP Top 10 coverage             â”‚
â”‚  â”œâ”€ crAPI (Python/JS)     137 findings   OWASP API Top 10                  â”‚
â”‚  â”œâ”€ NodeGoat (JS)          93 findings   Node.js security patterns         â”‚
â”‚  â”œâ”€ WebGoat (Java)      1,871 findings   399 Java files, 222 secrets       â”‚
â”‚  â””â”€ DVNA (JS)             252 findings   32 critical, 58 high              â”‚
â”‚                                                                             â”‚
â”‚  TIER 2 (Language-Specific - 6 repos):                                      â”‚
â”‚  â”œâ”€ RailsGoat (Ruby)      507 findings   First Ruby repo tested            â”‚
â”‚  â”œâ”€ Django.nV (Python)    646 findings   25 critical, 63 high              â”‚
â”‚  â”œâ”€ Flask App (Python)    393 findings   SSTI, Flask debug mode            â”‚
â”‚  â”œâ”€ DSVW (Python)          65 findings   Minimal app, high signal          â”‚
â”‚  â”œâ”€ OWASPWebGoatPHP     3,400 findings   211 critical, 1582 high           â”‚
â”‚  â””â”€ VulnerableApp (Java)  289 findings   Java security patterns            â”‚
â”‚                                                                             â”‚
â”‚  TIER 3 (Specialized - 8 repos):                                            â”‚
â”‚  â”œâ”€ VAmPI (REST API)      213 findings   OWASP API Top 10                  â”‚
â”‚  â”œâ”€ SSRF Lab               23 findings   Server-side request forgery       â”‚
â”‚  â”œâ”€ xxelab (Java)         187 findings   XML External Entity               â”‚
â”‚  â”œâ”€ wrongsecrets          498 findings   Secret management                 â”‚
â”‚  â”œâ”€ github-actions-goat    14 findings   CI/CD security                    â”‚
â”‚  â”œâ”€ DVGA (GraphQL)      1,268 findings   GraphQL vulns                     â”‚
â”‚  â”œâ”€ Tiredful-API          397 findings   REST API security                 â”‚
â”‚  â””â”€ InsecureShop           10 findings   Android/Kotlin                    â”‚
â”‚                                                                             â”‚
â”‚  TIER 4 (Additional - 5 repos):                                             â”‚
â”‚  â”œâ”€ Hackazon (PHP)      3,341 findings   PHP e-commerce                    â”‚
â”‚  â”œâ”€ secDevLabs          4,856 findings   Multi-lang, largest repo          â”‚
â”‚  â”œâ”€ nodejs-goof           364 findings   172 Trivy dependency vulns        â”‚
â”‚  â”œâ”€ DVTA (.NET)            52 findings   46 critical secrets               â”‚
â”‚  â””â”€ iGoat-Swift            98 findings   iOS/Swift patterns                â”‚
â”‚                                                                             â”‚
â”‚  TIER 5 (Solidity/DeFi - 7 repos):                                          â”‚
â”‚  â”œâ”€ DeFiHackLabs       37,590 findings   674 real hacks (2017-2025)        â”‚
â”‚  â”œâ”€ sherlock-derby      1,444 findings   100% match with audit docs        â”‚
â”‚  â”œâ”€ numoen/pmmp         1,168 findings   AMM protocol                      â”‚
â”‚  â”œâ”€ Ethernaut           1,187 findings   Solidity CTF                      â”‚
â”‚  â”œâ”€ damn-vulnerable-defi  502 findings   18 DeFi challenges                â”‚
â”‚  â”œâ”€ dvd-foundry           349 findings   Foundry version                   â”‚
â”‚  â””â”€ code4rena-numoen    1,106 findings   7 crit, 78 high, 292 med          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Detection Coverage by Vulnerability Type**:
| Vulnerability | PHP | JS | Python | Java | Ruby | Solidity |
|--------------|-----|----|---------|----|------|----------|
| SQL Injection | âœ… | âœ… | âœ… | âœ… | âœ… | N/A |
| XSS | âœ… | âœ… | âœ… | âœ… | âœ… | N/A |
| Command Injection | âœ… | âœ… | âœ… | âœ… | âœ… | N/A |
| SSTI | âœ… | âœ… | âœ… | âš ï¸ | âœ… | N/A |
| Path Traversal | âœ… | âœ… | âœ… | âœ… | âœ… | N/A |
| SSRF | âœ… | âœ… | âœ… | âœ… | âœ… | N/A |
| XXE | âš ï¸ | âš ï¸ | âœ… | âœ… | âš ï¸ | N/A |
| Hardcoded Secrets | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| Vulnerable Deps | âœ… | âœ… | âœ… | âœ… | âœ… | N/A |
| Reentrancy | N/A | N/A | N/A | N/A | N/A | âœ… |
| Access Control | N/A | N/A | N/A | N/A | N/A | âœ… |

**What We DON'T Detect (Requires DAST/Manual)**:
- CSRF, Session Management, Brute Force (runtime behavior)
- Business Logic flaws (semantic understanding)
- Race Conditions (parallel execution)
- CSP/CORS policies (configuration testing)

## Semgrep Rule Guidelines

When adding rules to `scanner/rules/`:

1. **YAML syntax**: Quote patterns containing colons
   ```yaml
   # GOOD
   pattern: 'subprocess.call($CMD, shell=True)'

   # BAD - will fail validation
   pattern: subprocess.call($CMD, shell=True)
   ```

2. **Always validate** before deploying:
   ```bash
   semgrep --validate --config scanner/rules/core.yaml
   ```

3. **Include**:
   - Unique rule ID
   - Clear message
   - Severity (ERROR/WARNING/INFO)
   - Target languages

## Environment Variables

Frontend (.env):
- `PUBLIC_SUPABASE_URL`
- `PUBLIC_SUPABASE_ANON_KEY`
- `SCANNER_API_URL`

Scanner (Fly.io secrets):
- Set via `fly secrets set KEY=value`

## Deployment

**Frontend**: Auto-deploys via Vercel on push to main

**Scanner**: Manual deploy to Fly.io
```bash
cd scanner
fly deploy --remote-only --no-cache
```

## Code Style

- TypeScript for frontend
- Python for scanner
- No comments unless explaining complex logic
- Use existing patterns and utilities

## MCP Servers Configuration

### Public MCP Endpoint (No Install Required)
**URL:** `https://scanner.vibeship.co/mcp`

Add to Claude Desktop config (`claude_desktop_config.json`):
```json
{
  "mcpServers": {
    "vibeship-scanner": {
      "command": "npx",
      "args": ["mcp-remote", "https://scanner.vibeship.co/mcp"]
    }
  }
}
```

**Available Tools:**
- `scanner_scan` - Start a security scan on a GitHub repo
- `scanner_status` - Get scan status and results
- `scanner_lookup_cve` - Look up CVE details from NVD
- `scanner_lookup_cwe` - Look up CWE weakness details
- `scanner_get_fix` - Get fix guide for a specific finding
- `scanner_master_prompt` - Get comprehensive fix guide for all findings

### Local Development MCP
**Location:** `~/.claude/mcp-servers/vibeship-scanner/`

Additional tools for rule development:
- `validate_opengrep_rule` - Validate rule YAML before deployment

### Other MCP Servers
- **fetch** - HTTP requests for custom API queries
- **github** - Repository operations, PR creation (requires GITHUB_TOKEN)

## Security Rule Development Skill

Use the `security-rule-development` skill when:
- Creating new Opengrep detection rules
- Benchmarking against vulnerable repos
- Researching CVEs/CWEs for rule metadata
- Improving scanner coverage

Skill location: `~/.claude/skills/security-rule-development/`

## Visual Scan Reporting Format

When presenting scan results or comparing scans, ALWAYS use this visual format:

### 1. Scan Comparison Header
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  SCAN COMPARISON: [Repo Name]                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Before: [scan-id-1]  â†’  After: [scan-id-2]                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 2. Severity Distribution Chart
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SEVERITY DISTRIBUTION                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  CRITICAL  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  25  (+3)                       â”‚
â”‚  HIGH      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  75  (+5)   â”‚
â”‚  MEDIUM    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  49  (=)                  â”‚
â”‚  LOW       â–ˆâ–ˆâ–ˆ  5  (-1)                                         â”‚
â”‚  INFO      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  38  (+2)                       â”‚
â”‚                                                                 â”‚
â”‚  TOTAL: 192 findings  (was: 189, Î” +3)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Scanner Breakdown
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCANNER BREAKDOWN                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Scanner     â”‚  Before â”‚  After  â”‚  Change                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Opengrep    â”‚   100   â”‚   103   â”‚  +3 (new rules working)      â”‚
â”‚  Trivy       â”‚    77   â”‚    77   â”‚   = (no change)              â”‚
â”‚  Gitleaks    â”‚    19   â”‚    19   â”‚   = (no change)              â”‚
â”‚  npm audit   â”‚     0   â”‚     0   â”‚   = (no package.json)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TOTAL       â”‚   189   â”‚   192   â”‚  +3                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Coverage Gap Analysis
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VULNERABILITY COVERAGE                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  âœ… SQL Injection        [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%  (15/15)   â”‚
â”‚  âœ… XSS                   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]  95%  (19/20)   â”‚
â”‚  âœ… Command Injection     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%  (8/8)     â”‚
â”‚  âš ï¸  Path Traversal       [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  60%  (3/5)     â”‚
â”‚  âœ… Hardcoded Secrets     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%  (19/19)   â”‚
â”‚  âš ï¸  SSRF                 [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  40%  (2/5)     â”‚
â”‚  âŒ XXE                   [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]   0%  (0/2)     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. Missing Detections & Recommendations
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RECOMMENDED NEW RULES                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. [PRIORITY: HIGH] XXE Detection                              â”‚
â”‚     â””â”€ Languages: Java, PHP, Python                             â”‚
â”‚     â””â”€ Pattern: XML parser without disabling external entities  â”‚
â”‚                                                                 â”‚
â”‚  2. [PRIORITY: MEDIUM] SSRF via URL parsing                     â”‚
â”‚     â””â”€ Languages: Python, JavaScript, Go                        â”‚
â”‚     â””â”€ Pattern: User input in URL/HTTP request construction     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6. Rule Health Status
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RULE HEALTH                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Total Rules:     2204                                          â”‚
â”‚  Rules Applied:   2108                                          â”‚
â”‚  Parse Errors:    0  âœ… (was: 20)                               â”‚
â”‚  Files Scanned:   36                                            â”‚
â”‚  Scan Duration:   105s                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Usage
- Use this format after EVERY scan comparison
- Update the bar charts proportionally (1 block â‰ˆ 2-5 findings)
- Always show delta (+/-) when comparing scans
- Highlight gaps with âš ï¸ or âŒ symbols
- End with actionable recommendations

### 7. Repo Verification Table (PREFERRED FORMAT)

Use this format when verifying coverage against a repo's documented vulnerabilities:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  [REPO NAME] COVERAGE VERIFICATION                                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Scan ID: [scan-id]                                                          â•‘
â•‘  Total Findings: XX | Rules Matched: XX unique                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DOCUMENTED VULNERABILITIES vs DETECTIONS                                   â”‚
â”œâ”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ # â”‚ Vulnerability                   â”‚ SAST-Detect?  â”‚ Detected? â”‚ Rule IDs  â”‚
â”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1 â”‚ SQL Injection                   â”‚ YES           â”‚ [OK]      â”‚ py-sql-*  â”‚
â”‚ 2 â”‚ XSS Reflected                   â”‚ YES           â”‚ [OK]      â”‚ xss-*     â”‚
â”‚ 3 â”‚ Command Injection               â”‚ YES           â”‚ [OK]      â”‚ cmd-*     â”‚
â”‚ 4 â”‚ CSRF                            â”‚ NO (runtime)  â”‚ N/A       â”‚ -         â”‚
â”‚ 5 â”‚ Missing Vulnerability           â”‚ YES           â”‚ [MISS]    â”‚ -         â”‚
â”‚ 6 â”‚ Partial Detection               â”‚ YES           â”‚ [PART]    â”‚ some-rule â”‚
â”œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  BONUS DETECTIONS (not documented but found):                               â”‚
â”‚  - Extra Finding 1: rule-id-here                                            â”‚
â”‚  - Extra Finding 2: rule-id-here                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SAST-Detectable: X/Y vulnerabilities
Detected: X/Y = XX%
Missing: [List gaps that need rules]
```

**Detection Status Tags:**
- `[OK]` = Fully detected with evidence
- `[PART]` = Partially detected (some instances missed)
- `[MISS]` = Should be detectable but not found
- `N/A` = Not SAST-detectable (runtime/DAST only)

**Color Enhancement (when supported):**
- ğŸŸ¢ `[OK]` - Green for detected
- ğŸŸ¡ `[PART]` - Yellow for partial
- ğŸ”´ `[MISS]` - Red for missing (needs rule)
- âšª `N/A` - Gray for not applicable

This format provides:
1. Clear header with scan metadata
2. Line-by-line vulnerability verification
3. SAST-detectability classification
4. Rule ID evidence for detections
5. Bonus findings not in documentation
6. Summary with exact coverage percentage

---

## CRITICAL: Benchmark Methodology (MUST FOLLOW)

**NO HALLUCINATIONS ALLOWED** - Only document what is actually detected vs what repos claim.

### Benchmark Verification Protocol

For EVERY vulnerable repository scanned, you MUST:

1. **Research Documented Vulnerabilities**
   - Read the repo's README, wiki, and documentation
   - List EVERY vulnerability type the repo claims to contain
   - Record the SOURCE of each claim (README line, wiki page, etc.)

2. **Compare Against Scan Results**
   - Query actual findings from Supabase
   - Map each finding to a documented vulnerability
   - Calculate ACTUAL detection rate: `(detected / documented) Ã— 100%`

3. **Document with Evidence**
   - Use the Verified Coverage Table format below
   - Mark status based on ACTUAL detection, not assumptions
   - Include specific rule IDs that detected each vuln

4. **Update SECURITY_TEST_PROCEDURE.md**
   - Add verified coverage table for each repo
   - Include the tier summary graph
   - Calculate aggregate coverage per tier

### Verified Coverage Table Template (REQUIRED)

For each repo, create this exact table format:

```markdown
#### [Repo Name] ([Language]) - Verified Coverage

| # | Documented Vuln | Source | SAST-Detectable? | Detected? | Rule ID | Evidence |
|---|-----------------|--------|------------------|-----------|---------|----------|
| 1 | SQL Injection | README | âœ… Yes | âœ… | php-sqli-* | file.php:42 |
| 2 | XSS | README | âœ… Yes | âœ… | xss-* | app.js:15 |
| 3 | CSRF | Wiki | âŒ Runtime | â– N/A | - | Needs DAST |
| 4 | XXE | README | âœ… Yes | âŒ | - | MISSING |

**Coverage: 2/3 SAST-detectable = 67%**
**Gaps: XXE (needs rule)**
```

### Tier Coverage Graph Template (REQUIRED)

After each tier is complete, create this graph:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TIER [N] COVERAGE - [Category Name]                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. DVWA         [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘]  80% (8/10 detectable)  â”‚
â”‚  2. Juice Shop   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘]  90% (18/20)            â”‚
â”‚  3. NodeGoat     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (12/12)            â”‚
â”‚  4. crAPI        [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  60% (6/10)             â”‚
â”‚                                                                 â”‚
â”‚  TIER AVERAGE: 82.5%                                            â”‚
â”‚  GAPS: CSRF (all), DOM XSS (partial), SSRF (1 repo)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Status Symbols (STANDARDIZED)

| Symbol | Meaning | Use When |
|--------|---------|----------|
| âœ… | Verified Detected | Finding exists in scan with evidence |
| âš ï¸ | Partial | Some instances detected, others missed |
| âŒ | Not Detected | Vuln exists but no finding |
| â– | N/A | Not detectable by SAST (runtime/DAST) |
| â³ | Pending | Not yet verified |

### What Counts as "Detected"

A vulnerability is ONLY marked âœ… if:
1. The scan contains a finding for that vulnerability type
2. The finding is in a file that implements the vulnerability
3. The rule ID matches the vulnerability category

A vulnerability is âŒ if:
1. The repo documents it exists
2. It IS detectable by static analysis
3. Our scan did NOT find it

### Aggregate Coverage Calculation

```
Per-Repo Coverage = (SAST-detected vulns / SAST-detectable vulns) Ã— 100%
Tier Coverage = Average of all per-repo coverages
Overall Coverage = Weighted average across all tiers
```

### When to Update Benchmark

- After EVERY scan of a benchmark repo
- After adding/modifying Opengrep rules
- Before claiming any coverage percentage
- When preparing release notes

### Forbidden Practices

âŒ **NEVER claim detection without evidence from scan results**
âŒ **NEVER estimate coverage - calculate from actual data**
âŒ **NEVER mark âœ… without a specific finding/rule ID**
âŒ **NEVER skip verification for "obvious" detections**
âŒ **NEVER copy coverage claims from previous sessions without re-verifying**

---

## 100% COVERAGE METHODOLOGY (MANDATORY)

**Goal: 100% SAST coverage for every benchmark repo**

### Step 1: List ALL Documented Vulnerabilities
- Read repo's README, wiki, and source comments
- Extract every vulnerability the repo claims to contain
- Number them 1 through N

### Step 2: Classify Each Vulnerability
For each vulnerability, determine:

**SAST-Detectable (code patterns we CAN detect):**
- SQL Injection, XSS (server-side), Command Injection
- Path Traversal, SSRF, XXE, Deserialization
- Hardcoded secrets, Dangerous function calls
- SSTI, Open Redirect, Header Injection

**NOT SAST-Detectable (requires DAST/manual/runtime):**
- CSRF (token validation is runtime)
- DOM XSS (client-side JS execution)
- HTTP Parameter Pollution (server behavior)
- Clickjacking (missing header = config, not code)
- DoS (resource exhaustion is runtime)
- Session Management (runtime state)
- Business Logic Flaws (semantic)
- Race Conditions (parallel execution)

### Step 3: Iterate Until 100%

```
FOR each SAST-detectable vulnerability:
  IF not detected:
    1. Examine the EXACT source code pattern
    2. Write a Semgrep rule matching that pattern
    3. Deploy and rescan
    4. Verify detection with rule_id + line number
  UNTIL detected
```

### Step 4: Document Gaps Honestly

For any vulnerability we cannot detect, document WHY:

| Gap Type | Example | Can We Fix? | How? |
|----------|---------|-------------|------|
| Runtime behavior | CSRF token check | NO | Needs DAST |
| Client-side JS | DOM XSS | PARTIAL | Add JS rules |
| Config issue | Missing headers | PARTIAL | Header rules |
| Semantic | Business logic | NO | Manual review |
| Third-party | Use external tool | YES | Integrate tool |

### Step 5: Calculate Coverage

```
SAST Coverage = (Detected SAST-detectable) / (Total SAST-detectable) x 100%

Example (DSVW):
- Total vulns: 26
- SAST-detectable: 20
- Detected: 20
- Coverage: 20/20 = 100%
```

### Verified Benchmark Results

| Repo | Total Vulns | SAST-Detectable | Detected | Coverage | Scan ID |
|------|-------------|-----------------|----------|----------|---------|
| DVWA | 14 | 14 | 14 | 100% | - |
| DSVW | 26 | 20 | 20 | 100% | ea1b3b28 |
| crAPI | 18 | 4 | 4 | 100% | 9b9a519b |

#### crAPI Detailed Verification (Scan: 9b9a519b-8c95-4725-ab68-ff45a2d2608e)

**SAST-Detectable Challenges (4/4 = 100%):**

| Challenge | Type | Detected? | Rule ID | Evidence |
|-----------|------|-----------|---------|----------|
| Challenge 11 | SSRF | âœ… | py-ssrf-*, js-ssrf-* | services/workshop/api/utils/mock_log.py:22 |
| Challenge 12 | NoSQL Injection | âœ… | nosql-injection-* | services/community/api/views.py:47 |
| Challenge 13 | SQL Injection | âœ… | py-sql-injection-* | services/workshop/api/controllers/*.py |
| Challenge 15 | JWT Vulnerabilities | âœ… | jwt-* | services/identity/api/auth.py |

**NOT SAST-Detectable Challenges (14):**

| Challenge | Type | Why NOT SAST? |
|-----------|------|---------------|
| Challenge 1-3 | BOLA (Broken Object Level Auth) | Runtime authorization check - object ownership verified at runtime |
| Challenge 4-6 | Broken Authentication | Credential validation is runtime behavior |
| Challenge 7 | Excessive Data Exposure | API response filtering is runtime/design decision |
| Challenge 8 | Rate Limiting | Resource limits are runtime enforcement |
| Challenge 9-10 | BFLA (Broken Function Level Auth) | Role-based access is runtime state |
| Challenge 14 | Mass Assignment | Object binding is framework runtime behavior |
| Challenge 16 | Unauthenticated Access | Missing auth middleware is config/runtime |
| Challenge 17-18 | LLM Vulnerabilities | Prompt injection is semantic/runtime |

**crAPI Summary:**
- Total Challenges: 18
- SAST-Detectable: 4 (only code-pattern vulnerabilities)
- Detected: 4/4 = **100% SAST Coverage**
- NOT SAST-Detectable: 14 (requires DAST/manual testing)

### What's NOT Our Fault (Document These)

When coverage < 100%, be specific about WHY:

1. **Runtime-only**: CSRF, session management, rate limiting
2. **Client-side**: DOM XSS, browser-specific attacks
3. **Config-based**: Missing headers, CORS policies
4. **Semantic**: Business logic, authorization flaws
5. **External**: Needs DAST tool (Burp, ZAP, Nuclei)

**NEVER say "we can't detect X" without explaining if it's:**
- Impossible (runtime/semantic)
- Possible with effort (new rule needed)
- Possible with integration (external tool)

---
